{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from skimage import exposure\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import pandas as pd\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_IMAGE_SIZE=48\n",
    "emotion_dict = {0:'Neutral', 1:'Anger', 2:'Disgust', 3:'Fear', 4:'Happy', 5:'Sad', 6:'Surprise'}\n",
    "cmu_emotion_dict = {0:0, 1:1, 3:2, 4:3, 5:4, 6:5, 7:6}\n",
    "kaggle_emotion_dict = {0:1, 1:2, 2:3, 3:4, 4:5, 5:6, 6:0}\n",
    "kdef_emotion_dict = {'AF':3, 'AN':1, 'DI':2, 'HA':4, 'NE':0, 'SA':5, 'SU':6}\n",
    "jaffe_emotion_dict = {'AN':1, 'DI':2, 'FE':3, 'HA':4, 'NE':0, 'SA':5, 'SU':6}\n",
    "kdef_code = lambda x: kdef_emotion_dict[x]\n",
    "jaffe_code = lambda x: jaffe_emotion_dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileCleaner:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_image_filenames(self, root_dir='CMU Data/'):\n",
    "        \"\"\"\n",
    "        Traverse directory structure to retrieve filenames of images\n",
    "        Collects all images contained in all subdirectores of root_dir\n",
    "        root_dir: The folder in which to begin the walk\n",
    "        returns: a list of image file names \n",
    "        \"\"\"\n",
    "        image_filenames = []\n",
    "        for dirName, subdirList, fileList in os.walk(root_dir):\n",
    "            if root_dir == 'CMU Data/':\n",
    "                fileList = fileList[:4] + fileList[-4:]\n",
    "            for fname in fileList:\n",
    "                if '.JPG' in fname or '.png' in fname or '.jpg' in fname or '.tiff' in fname:\n",
    "                    if (root_dir == 'KDEF/' and fname[-5] == 'S') or root_dir != 'KDEF/':\n",
    "                        image_filenames.append(dirName + '/' + fname)\n",
    "        return image_filenames   \n",
    "\n",
    "    def square_image(self, image, new_size=128, source='CMU'):\n",
    "        \"\"\"\n",
    "        Transforms images from regtangles into squares\n",
    "        image: the image to be squared\n",
    "        new_size: the resulting size of the image\n",
    "        source: the source of the image (for determing offset from center)\n",
    "        returns: a squared image of the desired size\n",
    "        \"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            image = rgb2gray(image)\n",
    "        height, width = image.shape[0], image.shape[1]\n",
    "        height_start = (height - new_size)//2\n",
    "        width_start = (width - new_size)//2\n",
    "\n",
    "        if source == 'CMU':\n",
    "            width_start += 20\n",
    "        if source == 'KDEF':\n",
    "            height_start += 50\n",
    "        return image[height_start:height_start+new_size, width_start:width_start+new_size]\n",
    "\n",
    "    def downsample_image(self, image, source='CMU'):\n",
    "        \"\"\"\n",
    "        Reduce granularity of image\n",
    "        image: the image to downsample\n",
    "        source: the source of the image\n",
    "        returns: a downsampled image (48x48)\n",
    "        \"\"\"\n",
    "        if source=='CMU':\n",
    "            reshape = 5\n",
    "        if source=='JAFFE':\n",
    "            reshape = 4\n",
    "        if source == 'KDEF':\n",
    "            reshape=8\n",
    "        image = image[reshape:-reshape, reshape:-reshape]\n",
    "        block_size = (reshape,reshape)\n",
    "        return block_reduce(image, block_size, func=np.mean)\n",
    "\n",
    "    def generate_num(self, i):\n",
    "        \"\"\"\n",
    "        Generate an 8 digit string number from an int\n",
    "        \"\"\"\n",
    "        num = str(i)\n",
    "        while(len(num)) < 8:\n",
    "            num = '0' + num\n",
    "        return num\n",
    "\n",
    "    def process_images(self, image_links, new_size=300, source='CMU', \n",
    "                       root_dir='CMU Data/', file_extension='CMU Images/'):\n",
    "        \"\"\"\n",
    "        image_links: list of image filenames\n",
    "        new_size: new size of the images\n",
    "        source: the source of the images\n",
    "        root_dir: the directory containing the original images\n",
    "        file_extension: extension directory to save images\n",
    "        \"\"\"\n",
    "        for i, paths in enumerate(image_links):\n",
    "            raw_path, final_path = paths[0], paths[1]\n",
    "            if i == 10:\n",
    "                break\n",
    "            try:\n",
    "                if i % 100 == 0:\n",
    "                    print(f'Processing image {i}')\n",
    "\n",
    "                im = imread(raw_path).astype(np.float32)\n",
    "                im /= np.max(im)\n",
    "                im = exposure.rescale_intensity(im)\n",
    "                new_im = square_image(im, new_size=new_size, source=source)\n",
    "                imshow(new_im)\n",
    "                plt.show()\n",
    "                filename = 'All Images/Raw Images/' + file_extension + final_path\n",
    "                imsave(fname=filename, arr=new_im)\n",
    "                im = imread(filename)\n",
    "                print(np.max(im))\n",
    "                imshow(im)\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f'failed on iteration {i}')\n",
    "                print(f'filename: {raw_path}')\n",
    "\n",
    "    def convert_tiff_to_jpg(self, root_dir='jaffe/', end_dir='JPG Images/'):\n",
    "        \"\"\"\n",
    "        Converts images in tiff format to jpg format.\n",
    "        root_dir: the directory to find images\n",
    "        end_dir: the dirctory to save images\n",
    "        \"\"\"\n",
    "        image_paths = get_image_filenames(root_dir, single=True)\n",
    "        for i, path in enumerate(image_paths):\n",
    "            if i % 100 == 0:\n",
    "                print(f'iteration {i}')\n",
    "            try:\n",
    "                im = tifffile.imread( path ).astype(np.float32)\n",
    "                if len(im.shape) > 2:\n",
    "                    im = im[:,:,0]\n",
    "                im /= np.max(im)\n",
    "\n",
    "                path_extension = path.split('/')[-1]\n",
    "                imsave(root_dir + end_dir + path_extension[:-5] + '.jpg', im, cmap='grey')\n",
    "            except Exception as e:\n",
    "                print(f'iteration {i}')\n",
    "                print(f'path: {path}')\n",
    "\n",
    "    def read_images_from_csv(self, file_paths, filename='Kaggle Data/fer2013.csv'):\n",
    "        \"\"\"\n",
    "        Reads images from a csv file\n",
    "        file_paths: list of image paths\n",
    "        filename: the filename of the csv file containing \n",
    "                  pixel intensity values\n",
    "        \"\"\"\n",
    "        with open(filename) as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            next(spamreader)\n",
    "            i = 0\n",
    "            for row in spamreader:\n",
    "                if i % 1000 == 0:\n",
    "                    print(f'iteration {i}')\n",
    "                image = np.array(row[1].strip().split(), dtype=np.float32)\n",
    "                image = image.reshape((48,48))\n",
    "                image /= 255\n",
    "                image /= np.max(image)\n",
    "                num = generate_num(i)\n",
    "                filename = 'All Images/Downsampled Images/' + file_paths[i]\n",
    "                i += 1\n",
    "            print(i)\n",
    "\n",
    "    def downsample_images(self, image_paths, base_dir='All Images/Raw Images/', \n",
    "                          extension_dir='CMU Images/', source='CMU'):\n",
    "        \"\"\"\n",
    "        Downsample a batch of images. Saves downsampled images.\n",
    "        base_dir: the base directory to which we save the images\n",
    "        extension_dir: extension directory to save the images\n",
    "        source: the source of the images\n",
    "        \"\"\"\n",
    "        for i, path in enumerate(image_paths):\n",
    "            path = path[1]\n",
    "            if i % 1000 == 0:\n",
    "                print(f'iteration {i}')\n",
    "            try:\n",
    "                im = imread(base_dir + extension_dir + path).astype(np.float32)\n",
    "                im /= 255.\n",
    "                filename = 'All Images/Downsampled Images/' + path\n",
    "                imsave(fname=filename, arr=downsample_image(im, source=source), cmap='gray')\n",
    "            except Exception as e:\n",
    "                print(f'iteration {i}')\n",
    "                print(f'filename: {path}')\n",
    "\n",
    "    def find_cmu_image_labels(self, path):\n",
    "        \"\"\"\n",
    "        Determine the label for CMU image\n",
    "        path: image path\n",
    "        returns: the emotion label asociated with the image\n",
    "        \"\"\"\n",
    "        path = path.split('/')\n",
    "        # get image number\n",
    "        number = int(path[-1][-9:-4])\n",
    "        if number < 5:\n",
    "            return 0\n",
    "        else:\n",
    "            path[1] = 'Emotion'\n",
    "            emo_file_dir = '/'.join(path[:-1])\n",
    "            # find file containing emotion label\n",
    "            for dirName, subdirList, fileList in os.walk(emo_file_dir):\n",
    "                if len(fileList) == 0:\n",
    "                    return 'NONE'\n",
    "                with open(dirName + '/' + fileList[0]) as f:\n",
    "                    label = int(float(f.readline().strip()))\n",
    "                    if label == 2:\n",
    "                        return 'NONE'\n",
    "                    return cmu_emotion_dict[label]\n",
    "\n",
    "    def find_image_labels(self, image_paths, source='CMU'):\n",
    "        \"\"\"\n",
    "        Locate the emotion label for each image\n",
    "        image_paths: a list of paths to images\n",
    "        source: the source of the image\n",
    "        returns: list of emotion labels for the image paths \n",
    "        \"\"\"\n",
    "        emotion_labels = []\n",
    "        for path in image_paths:\n",
    "            if source == 'CMU':\n",
    "                emotion_labels.append(find_cmu_image_labels(path))\n",
    "            elif source == 'KDEF':\n",
    "                code = path.split('/')[-1][4:6]\n",
    "                emotion_labels.append(kdef_code(code))\n",
    "            elif source == 'JAFFE':\n",
    "                code = path.split('/')[-1][3:5]\n",
    "                emotion_labels.append(jaffe_code(code))\n",
    "            else:\n",
    "                emotion_labels.append('NONE')\n",
    "        return emotion_labels\n",
    "\n",
    "    def label_images(self, image_paths, source='CMU', filename='All Images/emotion_labels.csv'):\n",
    "        \"\"\"\n",
    "        Label images with their corresponding emotions\n",
    "        image_paths: a list of paths to original images\n",
    "        source: the source of the images\n",
    "        filename: the file to write out the emotion labels\n",
    "        return: a list of (original image path, updated image path) tuples\n",
    "        \"\"\"\n",
    "        labeled_paths = []\n",
    "        emotion_labels = find_image_labels(image_paths, source)\n",
    "        with open(filename, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            i = 0\n",
    "            for path, label in zip(image_paths, emotion_labels):\n",
    "                if label == 'NONE':\n",
    "                    continue\n",
    "                num = generate_num(i)\n",
    "                final_path = source + '_' + num + '.jpg'\n",
    "                writer.writerow([final_path, label])\n",
    "                labeled_paths.append((path, final_path))\n",
    "                i += 1\n",
    "        return labeled_paths\n",
    "\n",
    "    def label_csv_images(self, data_file='Kaggle Data/fer2013.csv', \n",
    "                         label_file='All Images/emotion_labels.csv'):\n",
    "        \"\"\"\n",
    "        Label images originally in csv format\n",
    "        data_file: the file containing the labels for the csv images\n",
    "        label_file: the file to which I am writing labels\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        labeled_paths = []\n",
    "        with open(data_file, 'r') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            next(spamreader)\n",
    "            for row in spamreader:\n",
    "                label = kaggle_emotion_dict[int(row[0])]\n",
    "                labels.append(label)\n",
    "\n",
    "        with open(label_file, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            i = 0\n",
    "            for label in labels:\n",
    "                if label == 'NONE':\n",
    "                    continue\n",
    "                num = generate_num(i)\n",
    "                final_path = 'KAGGLE_' + num + '.jpg'\n",
    "                writer.writerow([final_path, label])\n",
    "                labeled_paths.append(final_path)\n",
    "                i += 1\n",
    "        return labeled_paths    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'All Images/Raw Images/CMU Images/CMU_00003169.jpg'\n",
    "im = imread(sample)\n",
    "down_im = downsample_image(im, source='CMU')\n",
    "print(down_im.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_dataframe(self, filename='All Images/emotion_labels.csv'):\n",
    "        \"\"\"\n",
    "        Load dataframe from file\n",
    "        filename: csv containing image information\n",
    "        returns: dataframe with image features\n",
    "        \"\"\"\n",
    "        image_features = pd.read_csv(filename)\n",
    "        image_features.columns = ['Filename', 'Emotion']\n",
    "        return image_features\n",
    "\n",
    "    def edge_detection(self, image_filenames):\n",
    "        \"\"\"\n",
    "        Detects edges in images with 4 methods\n",
    "        image_filenames: list of image filenames\n",
    "        returns: laplacian, sobel_x, sobel_y and sobel_comb images\n",
    "        \"\"\"\n",
    "        laplacian = []\n",
    "        sobel_x = []\n",
    "        sobel_y = []\n",
    "        sobel_comb = []\n",
    "        for i, filename in enumerate(image_filenames):\n",
    "            if i % 1000 == 0:\n",
    "                print(f'iteration {i}')\n",
    "            img = cv2.imread('All Images/Downsampled Images/' + filename,0)\n",
    "\n",
    "            laplacian_img = cv2.Laplacian(img,cv2.CV_64F)\n",
    "            sobel_x_img = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "            sobel_y_img = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "            sobel_comb_img = (sobel_x_img + sobel_y_img)/2.\n",
    "\n",
    "            laplacian_img += abs(np.min(laplacian_img))\n",
    "            laplacian_img /= np.max(laplacian_img)\n",
    "\n",
    "            sobel_x_img += abs(np.min(sobel_x_img))\n",
    "            sobel_x_img /= np.max(sobel_x_img)\n",
    "\n",
    "            sobel_y_img += abs(np.min(sobel_y_img))\n",
    "            sobel_y_img /= np.max(sobel_y_img)\n",
    "\n",
    "            sobel_comb_img += abs(np.min(sobel_comb_img))\n",
    "            sobel_comb_img /= np.max(sobel_comb_img)\n",
    "\n",
    "            imsave('All Images/Laplacian Images/' + filename, arr=laplacian_img)\n",
    "            imsave('All Images/SobelX Images/' + filename, arr=sobel_x_img)\n",
    "            imsave('All Images/SobelY Images/' + filename, arr=sobel_y_img)\n",
    "            imsave('All Images/SobelComb Images/' + filename, arr=sobel_comb_img)\n",
    "\n",
    "            laplacian.append('Laplacian Images/' + filename)\n",
    "            sobel_x.append('SobelX Images/' + filename)\n",
    "            sobel_y.append('SobelY Images/' + filename)\n",
    "            sobel_comb.append('SobelComb Images/' + filename)\n",
    "        return laplacian, sobel_x, sobel_y, sobel_comb\n",
    "\n",
    "    def feature_detection(self, image_filenames):\n",
    "        \"\"\"\n",
    "        Detects strong corners in images\n",
    "        image_filenames: list of image filenames\n",
    "        returns: list of corner coordinates\n",
    "        \"\"\"\n",
    "        corner_coordinates = []\n",
    "        for i, filename in enumerate(image_filenames):\n",
    "            if i % 1000 == 0:\n",
    "                print(f'iteration {i}')\n",
    "            img = cv2.imread('All Images/Downsampled Images/' + filename,0)\n",
    "            corners = cv2.goodFeaturesToTrack(img, minDistance=10, qualityLevel=0.01,maxCorners=10)\n",
    "\n",
    "            if corners is None:\n",
    "                print(filename)\n",
    "                corner_coordinates.append('NA')\n",
    "            else:\n",
    "                corners = np.int0(corners)\n",
    "                corners.reshape(corners.shape[0],2)\n",
    "                corner_coordinates.append(str(corners))\n",
    "        return corner_coordinates\n",
    "\n",
    "    def get_image_sources(self, df):\n",
    "        \"\"\"\n",
    "        Get source of images\n",
    "        df: dataframe containing image filenames\n",
    "        returns: list of image sources\n",
    "        \"\"\"\n",
    "        image_sources = []\n",
    "        fileList = df['Filename']\n",
    "        image_types = ['CMU', 'JAFFE', 'KDEF', 'KAGGLE']\n",
    "        for file in fileList:\n",
    "            for image_type in image_types:\n",
    "                if image_type in file:\n",
    "                    image_sources.append(image_type)\n",
    "                    continue\n",
    "        return image_sources\n",
    "\n",
    "    def get_image_emotion_str(self, df):\n",
    "        \"\"\"\n",
    "        Get string representation of image emotions\n",
    "        df: dataframe containing integer representation of emotions\n",
    "        \"\"\"\n",
    "        emotion_strs = []\n",
    "        emotion_ints = df['Emotion']\n",
    "        file_list = df['Filename']\n",
    "        for emotion, file in zip(emotion_ints, file_list):\n",
    "            try:\n",
    "                emotion_strs.append(emotion_dict[int(emotion)])\n",
    "            except Exception as e:\n",
    "                print(file)\n",
    "                im = imread('All Images/Downsampled Images/' + file)\n",
    "                imshow(im)\n",
    "                plt.show()\n",
    "        return emotion_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cleaner = FileCleaner()\n",
    "\n",
    "# Create file with all labels\n",
    "file_cleaner.convert_tiff_to_jpg(root_dir='jaffe/', end_dir='JPG Images/')\n",
    "cmu_final_paths = file_cleaner.label_images(get_image_filenames(root_dir='CMU Data/'), source='CMU')\n",
    "jaffe_final_paths = file_cleaner.label_images(get_image_filenames(root_dir='jaffe/JPG Images/'), source='JAFFE')\n",
    "kdef_final_paths = file_cleaner.label_images(get_image_filenames(root_dir='KDEF/'), source='KDEF')\n",
    "kaggle_final_paths = file_cleaner.label_csv_images()\n",
    "\n",
    "# Filter images to remove duplicates, and keep only images with labels\n",
    "file_cleaner.process_images(cmu_final_paths, new_size=250, source='CMU', file_extension='CMU Images/')\n",
    "file_cleaner.process_images(jaffe_final_paths, new_size=200, source='JAFFE', root_dir='jaffe/JPG Images', file_extension='JAFFE Images/')\n",
    "file_cleaner.process_images(kdef_final_paths, new_size=400, source='KDEF', root_dir='KDEF/', file_extension='KDEF Images/')\n",
    "read_images_from_csv(kaggle_final_paths, filename='Kaggle Data/fer2013.csv')\n",
    "\n",
    "# Downsampling images to increase size of dataset\n",
    "downsample_images(cmu_final_paths, extension_dir='CMU Images/', source='CMU')\n",
    "downsample_images(jaffe_final_paths, extension_dir='JAFFE Images/', source='JAFFE')\n",
    "downsample_images(kdef_final_paths, extension_dir='KDEF Images/', source='KDEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineer = FetureEngineer()\n",
    "\n",
    "# enhance image feature dataframe with new columns\n",
    "image_features = pd.DataFrame.from_csv('image_features.csv')\n",
    "image_features = feature_engineer.load_dataframe()\n",
    "laplacian, sobel_x, sobel_y, sobel_comb = feature_engineer.edge_detection(image_features['Filename'])\n",
    "corners = feature_engineer.feature_detection(image_features['Filename'])\n",
    "sources = feature_engineer.get_image_sources(image_features)\n",
    "emotion_strs = feature_engineer.get_image_emotion_str(image_features)\n",
    "\n",
    "image_features['Source'] = sources\n",
    "image_features['EmotionStr'] = emotion_strs\n",
    "image_features['Laplacian'] = laplacian\n",
    "image_features['SobelX'] = sobel_x\n",
    "image_features['SobelY'] = sobel_y\n",
    "image_features['SobelComb'] = sobel_comb\n",
    "image_features['Corners'] = corners\n",
    "\n",
    "image_features = image_features.dropna()\n",
    "image_features.to_csv(path_or_buf='image_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
